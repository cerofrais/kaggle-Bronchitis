{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alexnet with pretrained +finetunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "from PIL import Image\n",
    "import pretrainedmodels.utils as utils\n",
    "import pretrainedmodels\n",
    "plt.ion()   # interactive mode\n",
    "#import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y=pd.read_csv(\"Datasets/Bronchitis/Train_Labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Images</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>CR_0002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>CR_0005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>CR_0006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>CR_0007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>CR_0008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Images  Labels\n",
       "241  CR_0002       0\n",
       "92   CR_0005       0\n",
       "503  CR_0006       0\n",
       "244  CR_0007       0\n",
       "362  CR_0008       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y=df_y.sort_values(by=['Images'])\n",
    "df_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    324\n",
       "1    316\n",
       "Name: Labels, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(df_y.Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_y=np.array(df_y.Labels)\n",
    "labels=labels_y[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train_path=[]\n",
    "image_test_path=[]\n",
    "for path in os.listdir('Datasets/Bronchitis/Train_Images'):\n",
    "    if 'png'in path:\n",
    "        image_train_path.append('Datasets/Bronchitis/Train_Images/'+path)\n",
    "for path in os.listdir('Datasets/Bronchitis/Test_Images'):\n",
    "    if 'png'in path:\n",
    "        image_test_path.append('Datasets/Bronchitis/Test_Images/'+path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "images_train=[]\n",
    "for i in image_train_path[:20]:\n",
    "    x=cv2.imread(i)\n",
    "    resized_image = cv2.resize(x, (224,224)) \n",
    "    images_train.append(resized_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(images_train[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.imshow(images_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dset_classes_number = 2\n",
    "#model_ft = models.densenet121(pretrained=True)\n",
    "#model_ft.classifier = nn.Linear(1024, dset_classes_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class Densenet161(nn.Module):\n",
    "    def __init__(self, num_classes = 2):\n",
    "        super(Densenet161,self).__init__()\n",
    "        original_model = models.densenet161()\n",
    "        self.features = nn.Sequential(*list(original_model.children())[:-1])\n",
    "        self.classifier = (nn.Linear(2208, num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        f = self.features(x)\n",
    "        f = F.relu(f, inplace=True)\n",
    "        f = F.avg_pool2d(f, kernel_size=7).view(f.size(0), -1)\n",
    "        y = self.classifier(f)\n",
    "        return f,y\n",
    "\n",
    "\n",
    "x = Densenet161()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inp = Variable(torch.randn(4, 3, 224, 224))\n",
    "\n",
    "out = x(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "### Directory\n",
    "data_dir = 'Newbronchdataset'\n",
    "## loading train and validation image datasetsconvnet\n",
    "image_datasets = {x: dsets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class0', 'class1']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=5):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in dataloaders[phase]:\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    inputs = Variable(inputs.cuda())\n",
    "                    labels = Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data[0] * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    for i, data in enumerate(dataloaders['val']):\n",
    "        inputs, labels = data\n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "        for j in range(inputs.size()[0]):\n",
    "            images_so_far += 1\n",
    "            ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "            ax.axis('off')\n",
    "            ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "            imshow(inputs.cpu().data[j])\n",
    "\n",
    "            if images_so_far == num_images:\n",
    "                model.train(mode=was_training)\n",
    "                return\n",
    "    model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_ft = models.resnet18(pretrained=True)\n",
    "model_ft=models.alexnet(pretrained=True)\n",
    "#num_ftrs = model_ft.fc.in_features\n",
    "#model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "model_ft.classifier  = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 2),\n",
    ")\n",
    "#if use_gpu:\n",
    "#    model_ft = model_ft.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 0.7989 Acc: 0.4722\n",
      "val Loss: 0.7070 Acc: 0.4696\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 0.7043 Acc: 0.5222\n",
      "val Loss: 0.7160 Acc: 0.4739\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 0.6911 Acc: 0.5222\n",
      "val Loss: 0.7493 Acc: 0.4783\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 0.6948 Acc: 0.5778\n",
      "val Loss: 0.7003 Acc: 0.5022\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 0.6998 Acc: 0.5389\n",
      "val Loss: 0.7000 Acc: 0.4913\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 0.6894 Acc: 0.5833\n",
      "val Loss: 0.6982 Acc: 0.4957\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 0.6918 Acc: 0.5556\n",
      "val Loss: 0.7035 Acc: 0.4804\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 0.6825 Acc: 0.5833\n",
      "val Loss: 0.7022 Acc: 0.4804\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 0.6858 Acc: 0.5722\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=50)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from PIL import Image\n",
    "trans = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "def image_loader(image_name):\n",
    "    \"\"\"load image, returns cuda tensor\"\"\"\n",
    "    image = Image.open(image_name)\n",
    "    image = loader(image)\n",
    "    image=trans(image)\n",
    "    image = Variable(image, requires_grad=True)\n",
    "    image = image.unsqueeze(0)  #this is for VGG, may not be needed for ResNet\n",
    "    #image = image.unsqueeze(1)\n",
    "    return image#.cuda()  #assumes that you're using GPU\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#https://github.com/Cadene/pretrained-models.pytorch#installation\n",
    "from PIL import Image\n",
    "import pretrainedmodels.utils as utils\n",
    "\n",
    "load_img = utils.LoadImage()\n",
    "\n",
    "imsize = 224\n",
    "loader = transforms.Compose([transforms.Scale(imsize), transforms.ToTensor(),transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "        \n",
    "def image_loader(image_name):\n",
    "    \"\"\"load image, returns cuda tensor\"\"\"\n",
    "    #image = Image.open(image_name)\n",
    "    image = load_img(image_name)\n",
    "    image = loader(image).float()\n",
    "    image = Variable(image, requires_grad=True)\n",
    "    image = image.unsqueeze(0)  #this is for VGG, may not be needed for ResNet\n",
    "    return image#.cuda()  #assumes that you're using GPU\n",
    "\n",
    "\n",
    "image = image_loader('Datasets/Bronchitis/Test_Images/CR_0001.png')\n",
    "\n",
    "model_ft(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_img = utils.LoadImage()\n",
    "sub=[]\n",
    "# transformations depending on the model\n",
    "# rescale, center crop, normalize, and others (ex: ToBGR, ToRange255)\n",
    "#tf_img = utils.TransformImage(model) \n",
    "loader = transforms.Compose([transforms.Scale(224), transforms.ToTensor(),transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "#path_img = 'Datasets/Bronchitis/Test_Images/CR_0001.png'\n",
    "for each in image_test_path:\n",
    "    path_image=each\n",
    "    input_img = load_img(path_img)\n",
    "\n",
    "    input_tensor = loader(input_img)         # 3x400x225 -> 3x299x299 size may differ\n",
    "    input_tensor = input_tensor.unsqueeze(0) # 3x299x299 -> 1x3x299x299\n",
    "    input_i = torch.autograd.Variable(input_tensor,requires_grad=False)\n",
    "\n",
    "    output_logits = model_ft(input_i)\n",
    "    a=(output_logits.data).numpy()\n",
    "    if a[0][0]>a[0][1]:\n",
    "        sub.append(0)\n",
    "    else:\n",
    "        sub.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_logits"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "l=output_logits"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a=(l.data).numpy()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(a[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fil=open('subv1.csv','w')\n",
    "fil.write('Images,Labels')\n",
    "for i in range(len(sub)-1):\n",
    "    fil.write('%s,%d\\n'%(image_test_path[i][-11:-7],sub[i]))\n",
    "fil.write('%s,%d'%(image_test_path[i+1][-11:-7],sub[i+1]))\n",
    "fil.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
